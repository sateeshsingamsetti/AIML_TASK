# Optional: Drop columns that are not useful for modeling---------------- Gold layer
df = df.drop(columns=["id", "dataset"], errors='ignore')

# Encode categorical/string columns if not already done
categorical_cols = df.select_dtypes(include=["object", "category"]).columns

if len(categorical_cols) > 0:
    df[categorical_cols] = df[categorical_cols].apply(lambda col: col.astype("category").cat.codes)

# Ensure target exists
if "target" not in df.columns:
    df["target"] = (df["num"] > 0).astype(int)

# Drop 'num' if no longer needed
df.drop(columns=["num"], inplace=True, errors='ignore')

# Separate and scale
X = df.drop("target", axis=1)
y = df["target"]

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Combine scaled features and target
df_gold = X_scaled.copy()
df_gold["target"] = y
gold = db["heart_disease_gold"]
gold.insert_many(json.loads(df.to_json(orient="records")))